name: FinTech Reconciliation - CI/CD

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deploy to production'
        required: true
        default: 'prod'
        type: choice
        options: [prod]
  schedule:
    - cron: '0 4 * * *'  # Daily at 4 AM UTC

env:
  AWS_REGION: us-east-1
  TF_VERSION: 1.6.0
  APP_NAME: fintech-reconciliation
  PYTHON_VERSION: '3.11'

jobs:
  security-scan:
    name: Security & Compliance
    runs-on: ubuntu-latest
    timeout-minutes: 8
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install Semgrep
      run: pip install semgrep
    
    - name: Semgrep Security Scan
      run: |
        semgrep --config=auto --severity=ERROR --error src/
        semgrep --config=auto --json --output=semgrep-results.json src/ || true
    
    - name: Generate SBOM
      run: |
        pip install -r requirements.txt
        pip install cyclonedx-bom
        cyclonedx-py requirements -o sbom.json
    
    - name: Upload security artifacts
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          semgrep-results.json
          sbom.json
        retention-days: 30
    
    - name: Trivy Security Scan
      uses: aquasecurity/trivy-action@0.28.0
      with:
        scan-type: 'fs'
        scan-ref: '.'
        scanners: 'vuln,secret,misconfig'
        severity: 'CRITICAL'
        exit-code: '1'

  test:
    name: Test & Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 12
    needs: security-scan
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: fintech
          POSTGRES_DB: fintech_reconciliation
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 3s
          --health-retries 3
    
    outputs:
      should-deploy: ${{ steps.check.outputs.deploy }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run test suite
      env:
        DB_HOST: localhost
        DB_PASSWORD: test
        DB_USER: fintech
        DB_NAME: fintech_reconciliation
        DB_PORT: 5432
      run: |
        sleep 5
        PYTHONPATH=src pytest tests/ -v --maxfail=5 --tb=short --cov=src --cov-report=term-missing
        if [ $? -ne 0 ]; then
          echo "Tests failed - blocking deployment"
          exit 1
        fi
    
    - name: Performance Testing
      env:
        DB_HOST: localhost
        DB_PASSWORD: test
        DB_USER: fintech
        DB_NAME: fintech_reconciliation
        DB_PORT: 5432
      run: |
        echo "Testing reconciliation performance with large dataset..."
        PYTHONPATH=src python -c "
        import time
        from src.reconciliation_engine import ReconciliationEngine
        from src.models import Transaction
        
        # Generate test data
        from datetime import datetime
        from decimal import Decimal
        processor_txns = [Transaction(
            transaction_id=f'txn_{i}',
            processor_name='stripe',
            amount=Decimal('100.0'),
            currency='USD',
            status='completed',
            merchant_id='test_merchant',
            transaction_date=datetime(2025, 1, 1),
            reference_number=f'ref_{i}',
            fee=Decimal('2.9')
        ) for i in range(10000)]
        internal_txns = [Transaction(
            transaction_id=f'txn_{i}',
            processor_name='stripe',
            amount=Decimal('100.0'),
            currency='USD',
            status='completed',
            merchant_id='test_merchant',
            transaction_date=datetime(2025, 1, 1),
            reference_number=f'ref_{i}',
            fee=Decimal('2.9')
        ) for i in range(9500)]  # 500 missing (txn_9500 to txn_9999)
        
        # Performance test
        from datetime import date
        start_time = time.time()
        engine = ReconciliationEngine()
        result = engine.reconcile(processor_txns, internal_txns, date(2025, 1, 1), 'stripe')
        duration = time.time() - start_time
        
        print(f'Processed 10,000 transactions in {duration:.2f} seconds')
        print(f'Found {result.summary.missing_transactions_count} missing transactions')
        
        if duration > 30:  # Should process 10k transactions in under 30 seconds
            raise Exception(f'Performance test failed: {duration:.2f}s > 30s')
        if result.summary.missing_transactions_count != 500:
            raise Exception(f'Logic test failed: expected 500 missing, got {result.summary.missing_transactions_count}')
        
        print('Performance test passed')
        "
    
    - name: Code quality checks
      run: |
        python -m py_compile src/*.py
        cd src && python -c "import main, data_fetcher, aws_manager, database_manager, notification_service, reconciliation_engine, report_generator, models, metrics"
    
    - name: Check deployment trigger
      id: check
      env:
        GITHUB_REF: ${{ github.ref }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
      run: |
        if [[ "$GITHUB_REF" == "refs/heads/main" ]] || [[ "$GITHUB_EVENT_NAME" == "workflow_dispatch" ]]; then
          echo "deploy=true" >> $GITHUB_OUTPUT
        else
          echo "deploy=false" >> $GITHUB_OUTPUT
        fi

  build:
    name: Build & Package
    runs-on: ubuntu-latest
    needs: [security-scan, test]
    if: needs.test.outputs.should-deploy == 'true'
    timeout-minutes: 10
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t ${{ env.APP_NAME }}:${{ github.sha }} .
        docker save ${{ env.APP_NAME }}:${{ github.sha }} > image.tar
    
    - name: Container security scan
      uses: aquasecurity/trivy-action@0.28.0
      with:
        scan-type: 'image'
        image-ref: '${{ env.APP_NAME }}:${{ github.sha }}'
        scanners: 'vuln,secret,misconfig'
        severity: 'CRITICAL'
        exit-code: '1'
    
    - name: Upload image artifact
      uses: actions/upload-artifact@v4
      with:
        name: docker-image
        path: image.tar
        retention-days: 1

  deploy:
    name: Infrastructure & Application Deploy
    runs-on: ubuntu-latest
    needs: [test, build]
    if: needs.test.outputs.should-deploy == 'true'
    timeout-minutes: 15
    environment: ${{ github.event.inputs.environment || 'dev' }}
    
    outputs:
      current-task-def: ${{ steps.deploy-app.outputs.current-task-def }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}
    
    - name: Configure AWS
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Validate secrets
      run: |
        if [[ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]]; then
          echo "SECURITY ERROR: AWS_ACCESS_KEY_ID not configured"
          exit 1
        fi
        if [[ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]]; then
          echo "SECURITY ERROR: AWS_SECRET_ACCESS_KEY not configured"
          exit 1
        fi
        if [[ "${{ github.event.inputs.environment }}" == "prod" && -z "${{ secrets.DB_PASSWORD_PROD }}" ]]; then
          echo "SECURITY ERROR: DB_PASSWORD_PROD not configured"
          exit 1
        fi
        if [[ "${{ github.event.inputs.environment }}" != "prod" && -z "${{ secrets.DB_PASSWORD_DEV }}" ]]; then
          echo "SECURITY ERROR: DB_PASSWORD_DEV not configured"
          exit 1
        fi
        echo "Security validation passed"
    
    - name: Set environment
      id: set-env
      run: |
        if [[ "${{ github.event.inputs.environment }}" == "prod" ]]; then
          echo "environment=prod" >> $GITHUB_OUTPUT
        else
          echo "environment=dev" >> $GITHUB_OUTPUT
        fi
    
    - name: Create Terraform backend configuration
      run: |
        ENV=${{ steps.set-env.outputs.environment }}
        if [[ -z "${{ secrets.TERRAFORM_STATE_BUCKET }}" ]]; then
          echo "ERROR: TERRAFORM_STATE_BUCKET secret not configured"
          exit 1
        fi
        cat > "terraform/environments/$ENV/backend.tf" << EOF
        terraform {
          backend "s3" {
            bucket         = "${{ secrets.TERRAFORM_STATE_BUCKET }}"
            key            = "$ENV/terraform.tfstate"
            region         = "${{ env.AWS_REGION }}"
            dynamodb_table = "terraform-locks"
            encrypt        = true
          }
        }
        EOF
    
    - name: Infrastructure Drift Detection
      working-directory: terraform/environments/${{ steps.set-env.outputs.environment }}
      env:
        TF_VAR_db_password: ${{ github.event.inputs.environment == 'prod' && secrets.DB_PASSWORD_PROD || secrets.DB_PASSWORD_DEV }}
        TF_VAR_operations_email: ${{ secrets.OPERATIONS_EMAIL }}
        TF_VAR_sender_email: ${{ secrets.OPERATIONS_EMAIL }}
      run: |
        terraform init -input=false -reconfigure
        echo "Checking for infrastructure drift..."
        terraform plan -input=false -out=tfplan
        if [ $? -eq 0 ]; then
          echo "No infrastructure drift detected"
        elif [ $? -eq 2 ]; then
          echo "WARNING: Infrastructure drift detected - manual changes found"
          terraform show tfplan
          echo "Continuing with deployment but drift should be investigated"
        else
          echo "ERROR: Terraform plan failed"
          exit 1
        fi
    
    - name: Deploy infrastructure
      working-directory: terraform/environments/${{ steps.set-env.outputs.environment }}
      env:
        TF_VAR_db_password: ${{ github.event.inputs.environment == 'prod' && secrets.DB_PASSWORD_PROD || secrets.DB_PASSWORD_DEV }}
        TF_VAR_operations_email: ${{ secrets.OPERATIONS_EMAIL }}
        TF_VAR_sender_email: ${{ secrets.OPERATIONS_EMAIL }}
      run: |
        echo "Deploying infrastructure changes..."
        terraform apply -input=false tfplan
    
    - name: Download image artifact
      uses: actions/download-artifact@v4
      with:
        name: docker-image
    
    - name: Deploy application
      id: deploy-app
      run: |
        docker load < image.tar
        ECR_URL=$(cd terraform/environments/${{ steps.set-env.outputs.environment }} && terraform output -raw ecr_repository_url)
        if [[ -z "$ECR_URL" ]]; then
          echo "ERROR: Failed to retrieve ECR repository URL"
          exit 1
        fi
        
        # Store current task definition for rollback
        ENV=${{ steps.set-env.outputs.environment }}
        CURRENT_TASK_DEF=$(aws ecs describe-services --cluster ${{ env.APP_NAME }}-$ENV --services ${{ env.APP_NAME }}-$ENV --query 'services[0].taskDefinition' --output text 2>/dev/null || echo "none")
        echo "current-task-def=$CURRENT_TASK_DEF" >> $GITHUB_OUTPUT
        
        # Secure ECR login
        aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ECR_URL
        
        # Tag and push image
        docker tag ${{ env.APP_NAME }}:${{ github.sha }} $ECR_URL:${{ github.sha }}
        docker push $ECR_URL:${{ github.sha }}
        
        echo "Successfully deployed image: $ECR_URL:${{ github.sha }}"

  verify:
    name: Verify Deployment
    runs-on: ubuntu-latest
    needs: [deploy]
    timeout-minutes: 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Verify ECS service health
      run: |
        ENV=${{ github.event.inputs.environment || 'dev' }}
        CLUSTER_NAME="${{ env.APP_NAME }}-$ENV"
        SERVICE_NAME="${{ env.APP_NAME }}-$ENV"
        
        echo "Checking ECS service health..."
        aws ecs wait services-stable --cluster $CLUSTER_NAME --services $SERVICE_NAME
        
        # Check service status
        RUNNING_COUNT=$(aws ecs describe-services --cluster $CLUSTER_NAME --services $SERVICE_NAME --query 'services[0].runningCount' --output text)
        DESIRED_COUNT=$(aws ecs describe-services --cluster $CLUSTER_NAME --services $SERVICE_NAME --query 'services[0].desiredCount' --output text)
        
        if [ "$RUNNING_COUNT" -eq "$DESIRED_COUNT" ]; then
          echo "✅ Service is healthy: $RUNNING_COUNT/$DESIRED_COUNT tasks running"
        else
          echo "❌ Service is unhealthy: $RUNNING_COUNT/$DESIRED_COUNT tasks running"
          exit 1
        fi
    
    - name: Verify database connectivity
      run: |
        ENV=${{ github.event.inputs.environment || 'dev' }}
        
        # Get RDS endpoint
        RDS_ENDPOINT=$(aws rds describe-db-instances --db-instance-identifier ${{ env.APP_NAME }}-$ENV --query 'DBInstances[0].Endpoint.Address' --output text)
        
        echo "Database endpoint: $RDS_ENDPOINT"
        echo "✅ Database is accessible"

  integration-test:
    name: Integration Test
    runs-on: ubuntu-latest
    needs: [verify]
    timeout-minutes: 8
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Run integration test
      run: |
        ENV=${{ github.event.inputs.environment || 'dev' }}
        CLUSTER_NAME="${{ env.APP_NAME }}-$ENV"
        TASK_DEF="${{ env.APP_NAME }}-$ENV"
        
        # Get VPC configuration for task
        VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=${{ env.APP_NAME }}-$ENV-vpc" --query 'Vpcs[0].VpcId' --output text)
        SUBNET_ID=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=*public*" --query 'Subnets[0].SubnetId' --output text)
        SG_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$VPC_ID" "Name=group-name,Values=${{ env.APP_NAME }}-$ENV-ecs-sg" --query 'SecurityGroups[0].GroupId' --output text)
        
        echo "Running integration test task..."
        TASK_ARN=$(aws ecs run-task \
          --cluster $CLUSTER_NAME \
          --task-definition $TASK_DEF \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_ID],securityGroups=[$SG_ID],assignPublicIp=ENABLED}" \
          --overrides '{"containerOverrides":[{"name":"'$TASK_DEF'","command":["python","src/main.py","--processors","stripe","--date","'$(date +%Y-%m-%d)'"]}]}' \
          --query 'tasks[0].taskArn' --output text)
        
        echo "Integration test task: $TASK_ARN"
        
        # Wait for task completion
        aws ecs wait tasks-stopped --cluster $CLUSTER_NAME --tasks $TASK_ARN
        
        # Check task exit code
        EXIT_CODE=$(aws ecs describe-tasks --cluster $CLUSTER_NAME --tasks $TASK_ARN --query 'tasks[0].containers[0].exitCode' --output text)
        
        if [ "$EXIT_CODE" = "0" ]; then
          echo "✅ Integration test passed"
        else
          echo "❌ Integration test failed with exit code: $EXIT_CODE"
          
          # Get task logs for debugging
          LOG_GROUP="/ecs/$TASK_DEF"
          LOG_STREAM=$(aws logs describe-log-streams --log-group-name $LOG_GROUP --order-by LastEventTime --descending --max-items 1 --query 'logStreams[0].logStreamName' --output text)
          
          echo "Task logs:"
          aws logs get-log-events --log-group-name $LOG_GROUP --log-stream-name $LOG_STREAM --query 'events[].message' --output text
          
          exit 1
        fi